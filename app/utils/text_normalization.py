"""
Shared text normalization utilities.

This module provides common text cleaning and normalization functions
used across company names, titles, and keywords utilities.

This module focuses on low-level text cleaning:
- Unicode normalization (special characters, mathematical symbols)
- Whitespace normalization
- Emoji removal
- Encoding issue fixes
- Wrapping quote removal
- Letter detection (multi-language support)

Used by:
- title_utils.py
- company_name_utils.py
- keyword_utils.py

Note: For service-layer normalization (handling None, placeholders, CSV exports),
see normalization.py which is used by service classes.
"""

import re
import unicodedata
from typing import Optional

from app.utils.logger import get_logger

logger = get_logger(__name__)

# Try to import emoji library, fallback if not available
try:
    import emoji
    HAS_EMOJI = True
except ImportError:
    HAS_EMOJI = False


def normalize_unicode(text: str) -> str:
    """
    Normalize Unicode characters to their standard forms.
    Converts special Unicode variants (like mathematical bold, sans-serif, etc.)
    to standard ASCII/Latin characters where possible.
    
    Args:
        text: Input text with potentially special Unicode characters
        
    Returns:
        Normalized text
    """
    # First, try to decompose and recompose
    text = unicodedata.normalize('NFKC', text)
    
    # Replace common Unicode variants with ASCII equivalents
    replacements = {
        # Mathematical bold
        'ð”¸': 'A', 'ð”¹': 'B', 'â„‚': 'C', 'ð”»': 'D', 'ð”¼': 'E', 'ð”½': 'F',
        'ð”¾': 'G', 'â„': 'H', 'ð•€': 'I', 'ð•': 'J', 'ð•‚': 'K', 'ð•ƒ': 'L',
        'ð•„': 'M', 'â„•': 'N', 'ð•†': 'O', 'â„™': 'P', 'â„š': 'Q', 'â„': 'R',
        'ð•Š': 'S', 'ð•‹': 'T', 'ð•Œ': 'U', 'ð•': 'V', 'ð•Ž': 'W', 'ð•': 'X',
        'ð•': 'Y', 'â„¤': 'Z',
        # Mathematical bold lowercase
        'ð•’': 'a', 'ð•“': 'b', 'ð•”': 'c', 'ð••': 'd', 'ð•–': 'e', 'ð•—': 'f',
        'ð•˜': 'g', 'ð•™': 'h', 'ð•š': 'i', 'ð•›': 'j', 'ð•œ': 'k', 'ð•': 'l',
        'ð•ž': 'm', 'ð•Ÿ': 'n', 'ð• ': 'o', 'ð•¡': 'p', 'ð•¢': 'q', 'ð•£': 'r',
        'ð•¤': 's', 'ð•¥': 't', 'ð•¦': 'u', 'ð•§': 'v', 'ð•¨': 'w', 'ð•©': 'x',
        'ð•ª': 'y', 'ð•«': 'z',
        # Mathematical sans-serif bold
        'ð—”': 'A', 'ð—•': 'B', 'ð—–': 'C', 'ð——': 'D', 'ð—˜': 'E', 'ð—™': 'F',
        'ð—š': 'G', 'ð—›': 'H', 'ð—œ': 'I', 'ð—': 'J', 'ð—ž': 'K', 'ð—Ÿ': 'L',
        'ð— ': 'M', 'ð—¡': 'N', 'ð—¢': 'O', 'ð—£': 'P', 'ð—¤': 'Q', 'ð—¥': 'R',
        'ð—¦': 'S', 'ð—§': 'T', 'ð—¨': 'U', 'ð—©': 'V', 'ð—ª': 'W', 'ð—«': 'X',
        'ð—¬': 'Y', 'ð—­': 'Z',
        # Mathematical sans-serif bold lowercase
        'ð—®': 'a', 'ð—¯': 'b', 'ð—°': 'c', 'ð—±': 'd', 'ð—²': 'e', 'ð—³': 'f',
        'ð—´': 'g', 'ð—µ': 'h', 'ð—¶': 'i', 'ð—·': 'j', 'ð—¸': 'k', 'ð—¹': 'l',
        'ð—º': 'm', 'ð—»': 'n', 'ð—¼': 'o', 'ð—½': 'p', 'ð—¾': 'q', 'ð—¿': 'r',
        'ð˜€': 's', 'ð˜': 't', 'ð˜‚': 'u', 'ð˜ƒ': 'v', 'ð˜„': 'w', 'ð˜…': 'x',
        'ð˜†': 'y', 'ð˜‡': 'z',
        # Mathematical italic
        'ð´': 'A', 'ðµ': 'B', 'ð¶': 'C', 'ð·': 'D', 'ð¸': 'E', 'ð¹': 'F',
        'ðº': 'G', 'ð»': 'H', 'ð¼': 'I', 'ð½': 'J', 'ð¾': 'K', 'ð¿': 'L',
        'ð‘€': 'M', 'ð‘': 'N', 'ð‘‚': 'O', 'ð‘ƒ': 'P', 'ð‘„': 'Q', 'ð‘…': 'R',
        'ð‘†': 'S', 'ð‘‡': 'T', 'ð‘ˆ': 'U', 'ð‘‰': 'V', 'ð‘Š': 'W', 'ð‘‹': 'X',
        'ð‘Œ': 'Y', 'ð‘': 'Z',
        # Mathematical italic lowercase
        'ð‘Ž': 'a', 'ð‘': 'b', 'ð‘': 'c', 'ð‘‘': 'd', 'ð‘’': 'e', 'ð‘“': 'f',
        'ð‘”': 'g', 'â„Ž': 'h', 'ð‘–': 'i', 'ð‘—': 'j', 'ð‘˜': 'k', 'ð‘™': 'l',
        'ð‘š': 'm', 'ð‘›': 'n', 'ð‘œ': 'o', 'ð‘': 'p', 'ð‘ž': 'q', 'ð‘Ÿ': 'r',
        'ð‘ ': 't', 'ð‘¡': 't', 'ð‘¢': 'u', 'ð‘£': 'v', 'ð‘¤': 'w', 'ð‘¥': 'x',
        'ð‘¦': 'y', 'ð‘§': 'z',
        # Fullwidth characters
        'ï¼¡': 'A', 'ï¼¢': 'B', 'ï¼£': 'C', 'ï¼¤': 'D', 'ï¼¥': 'E', 'ï¼¦': 'F',
        'ï¼§': 'G', 'ï¼¨': 'H', 'ï¼©': 'I', 'ï¼ª': 'J', 'ï¼«': 'K', 'ï¼¬': 'L',
        'ï¼­': 'M', 'ï¼®': 'N', 'ï¼¯': 'O', 'ï¼°': 'P', 'ï¼±': 'Q', 'ï¼²': 'R',
        'ï¼³': 'S', 'ï¼´': 'T', 'ï¼µ': 'U', 'ï¼¶': 'V', 'ï¼·': 'W', 'ï¼¸': 'X',
        'ï¼¹': 'Y', 'ï¼º': 'Z',
        'ï½': 'a', 'ï½‚': 'b', 'ï½ƒ': 'c', 'ï½„': 'd', 'ï½…': 'e', 'ï½†': 'f',
        'ï½‡': 'g', 'ï½ˆ': 'h', 'ï½‰': 'i', 'ï½Š': 'j', 'ï½‹': 'k', 'ï½Œ': 'l',
        'ï½': 'm', 'ï½Ž': 'n', 'ï½': 'o', 'ï½': 'p', 'ï½‘': 'q', 'ï½’': 'r',
        'ï½“': 's', 'ï½”': 't', 'ï½•': 'u', 'ï½–': 'v', 'ï½—': 'w', 'ï½˜': 'x',
        'ï½™': 'y', 'ï½š': 'z',
        # Replacement character
        '': '',  # Remove replacement characters
    }
    
    for old, new in replacements.items():
        text = text.replace(old, new)
    
    return text


def normalize_whitespace(text: str) -> str:
    """
    Normalize whitespace: remove leading/trailing, collapse multiple spaces.
    
    Args:
        text: Input text with potentially irregular whitespace
        
    Returns:
        Text with normalized whitespace
    """
    # Collapse multiple spaces to single space
    text = re.sub(r'\s+', ' ', text)
    # Strip leading and trailing whitespace
    text = text.strip()
    return text


def remove_wrapping_quotes(text: str) -> str:
    """
    Remove wrapping quotes (single or double) from text.
    Handles cases like: "Company Name", 'Company Name', "'Company Name'"
    
    Args:
        text: Input text potentially wrapped in quotes
        
    Returns:
        Text with wrapping quotes removed
    """
    text = text.strip()
    
    # Remove wrapping quotes (can be nested)
    while len(text) >= 2:
        if (text[0] == '"' and text[-1] == '"') or (text[0] == "'" and text[-1] == "'"):
            text = text[1:-1].strip()
        else:
            break
    
    return text


def remove_emojis(text: str) -> str:
    """
    Remove emojis and emoji-like symbols from text.
    
    Args:
        text: Input text potentially containing emojis
        
    Returns:
        Text with emojis removed
    """
    # Remove emojis using the emoji library if available
    if HAS_EMOJI:
        text = emoji.replace_emoji(text, replace='')
    
    # Remove other common symbols that might be used as emojis
    symbol_patterns = [
        r'[\U0001F300-\U0001F9FF]',  # Emoticons
        r'[\U00002600-\U000027BF]',  # Miscellaneous symbols
        r'[\U0001F600-\U0001F64F]',  # Emoticons
        r'[\U0001F680-\U0001F6FF]',  # Transport and map symbols
    ]
    
    for pattern in symbol_patterns:
        text = re.sub(pattern, '', text)
    
    return text


def contains_letters(text: str) -> bool:
    """
    Check if text contains at least one letter (any language).
    
    Supports:
    - ASCII letters (a-z, A-Z)
    - Unicode letters from all scripts (Chinese, Japanese, Arabic, Hebrew, Cyrillic, etc.)
    - Uses Unicode letter category (\\p{L}) which includes all language scripts
    
    Args:
        text: Text to check
        
    Returns:
        True if text contains at least one letter from any language
    """
    # Match letters from all Unicode scripts
    # This includes: Latin, Cyrillic, Arabic, Hebrew, Chinese, Japanese, Korean, etc.
    # Pattern matches any Unicode character in the range \u0080-\uFFFF (non-ASCII)
    # plus ASCII letters a-z, A-Z
    return bool(re.search(r'[a-zA-Z\u0080-\uFFFF]', text))


def fix_encoding_issues(text: str) -> str:
    """
    Attempt to fix common encoding issues.
    
    Args:
        text: Input text with potential encoding issues
        
    Returns:
        Text with encoding issues fixed where possible
    """
    # Remove replacement characters
    text = text.replace('', '')
    
    # Try to decode and re-encode to fix common issues
    try:
        # If text contains only question marks (common encoding replacement)
        if re.match(r'^\?+\s*\?*$', text.strip()):
            return ''  # Likely encoding corruption, return empty
    except Exception:
        pass  # Regex failed, continue with normalization
    
    return text

